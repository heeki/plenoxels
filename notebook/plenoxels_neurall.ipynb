{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbg9iHgVQjfs"
      },
      "source": [
        "This notebook is a modified version of the one found https://github.com/neurall/PlenoxelsColab \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Eho4tgYSAv2"
      },
      "outputs": [],
      "source": [
        "# Sadly. my 3080 while it is more than twice as fast as Colab Pro, it is still sitting idle due to just 10g gpu mem ending training attempts with out of gpu mem errors\n",
        "# So let's see what gpu colab given us in cloud (16g gpu mem is minumum for M60 tank sample dataset training and is given on Colab Pro instances).\n",
        "from psutil import virtual_memory\n",
        "\n",
        "gpuname = !nvidia-smi -L\n",
        "gpuname = str(gpuname).replace('PCIE-','').split('Tesla ')[1].split(' ')[0]\n",
        "\n",
        "print(gpuname)\n",
        "\n",
        "gpu_info = !nvidia-smi \n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('ERROR!!! Not connected to a GPU. Nothing will work')\n",
        "else:\n",
        "  gpu_mem = int(str(gpu_info).split('MiB / ')[1].split('MiB')[0])\n",
        "  print('You got '+str(gpu_mem)+' gpu mem ')\n",
        "  if gpu_mem < 16000:\n",
        "    print(gpu_info,'\\n\\nBEWARE!!! GPUs with less than 16g will fail with out of memory error with 512 voxel res in config. For 256 10g gpu is fine')\n",
        "  else:\n",
        "    print('which seems enough.')\n",
        "\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('BEWARE!!! Not using a high-RAM runtime of Colab Pro. 512 voxel cube training will fail on out of system memory which is just 12gb on Colab Free')\n",
        "else:\n",
        "  print('Great. You are using a high-RAM runtime '+str(int(ram_gb))+'Gb ! 27g is needed to train example M60 Tank dataset\\n')\n",
        "\n",
        "# one day colab will hopefully move to python 3.8 and higher\n",
        "!python --version\n",
        "\n",
        "# for faster compiles later\n",
        "!apt install -y -qq  ninja-build  &> /dev/null\n",
        "\n",
        "import multiprocessing\n",
        "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
        "%env MAX_JOBS={cores}\n",
        "\n",
        "# make sure that colmap is ready if needed to work on our own images later\n",
        "!apt install colmap &> /dev/null\n",
        "colmap_version = !colmap -h\n",
        "print (colmap_version[0])\n",
        "\n",
        "# this is key to fit in gpu mem. helps to lower gpu fragmentation alloc waste and in turn allows fitting 16g gpu mem typically present in cloud gpus as max\n",
        "# ie I was last time 20mb short instead of 2g short on gpu mem\n",
        "%env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:21\n",
        "\n",
        "#comment capture out to see cell outputs first time. I personally consider it unecessary super long distracting spam afterwards and cell execution done checkmark is all I need.\n",
        "#%%capture \n",
        "\n",
        "import os\n",
        "%cd '/content'\n",
        "if not os.path.exists('svox2'):\n",
        "  !git clone https://github.com/sxyu/svox2.git  &> /dev/null\n",
        "\n",
        "  # patch and make py sources again compatible with CoLab (python 3.7) \n",
        "  # by removing completely unnecesary 3.8 specific syntaxctic sugar from two lines\n",
        "  !sed -E -i \"s/\\{minv=:/minv=\\{minv:/g\"    /content/svox2/opt/opt.py \n",
        "  !sed -E -i \"s/\\{meanv=:/meanv=\\{meanv:/g\" /content/svox2/opt/opt.py \n",
        "  !sed -E -i \"s/\\{maxv=:/maxv=\\{maxv:/g\"    /content/svox2/opt/opt.py \n",
        "  !sed -E -i \"s/\\{minv=:/minv=\\{minv:/g\"    /content/svox2/opt/render_imgs.py \n",
        "  !sed -E -i \"s/\\{meanv=:/meanv=\\{meanv:/g\" /content/svox2/opt/render_imgs.py \n",
        "  !sed -E -i \"s/\\{maxv=:/maxv=\\{maxv:/g\"    /content/svox2/opt/render_imgs.py \n",
        "\n",
        "%cd svox2\n",
        "\n",
        "# There is no point in slow conda and multi env dance in this throwavay colab env anyway plus most packages from environment.yml are installed already.\n",
        "# So if we stick to colabs py 3.7 then biggest and most complex ones like pytorch cudatoolkit and most of environment.yml requirements is already present \n",
        "# and we need to install just 4 missing packages. \n",
        "# In short. By sticking to py 3.7 this colab can be restarted from factory reset state very fast without endless and useless huge long reinstalls\n",
        "\n",
        "!pip install imageio-ffmpeg &> /dev/null\n",
        "!pip install ipdb           &> /dev/null\n",
        "!pip install lpips          &> /dev/null\n",
        "!pip install pymcubes       &> /dev/null\n",
        "!pip install --upgrade --no-cache-dir gdown &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install colmap"
      ],
      "metadata": {
        "id": "yEun8YZWhKHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y xvfb"
      ],
      "metadata": {
        "id": "AWSNSFtorRop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kaYiQzjzApuo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7623d0d-9cbd-4279-a444-57873b560438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# To make env restarts even faster. It is perhaps good idea to use gdrive to cache once compiled pytorch wheel and later even checkpoint after training \n",
        "# so next time colab runtime resets and forgets all files next bootstrap is fast\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUqq8knldYD2"
      },
      "outputs": [],
      "source": [
        "# Because compile and install of pytorch wheel is soooo sloooow. We compile it just once first time we run this colab,\n",
        "# And then cache it on gdrive so next time we can do just 2s fast reinstall on each runtime restart instead of 20 min whl compile\n",
        "# But. Because we can get different gpu next time. We need to compile and cache multiple whl files for each  gpu we encounter and save whls to gdrive in dirs with gpu names\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "%cd /content/svox2\n",
        "\n",
        "# grab currenly assigned gpu model name (P100-16gb etc.)\n",
        "gpuname = !nvidia-smi -L\n",
        "gpuname = str(gpuname).replace('PCIE-','').split('Tesla ')[1].split(' ')[0]\n",
        "whlname = 'svox2-0.0.1.dev0+sphtexcub.lincolor.fast-cp37-cp37m-linux_x86_64.whl'\n",
        "whlpath = '/content/drive/MyDrive/'+gpuname+'/'+whlname\n",
        "print(gpuname)\n",
        "\n",
        "# compile this whl just once first time to obtain and cache it on gdrive\n",
        "if not os.path.exists(whlpath):\n",
        "  !apt install ninja-build\n",
        "  %env MAX_JOBS=4\n",
        "  !python setup.py bdist_wheel &> /dev/null\n",
        "  !mkdir /content/drive/MyDrive/{gpuname}\n",
        "  !cp ./dist/{whlname} {whlpath}\n",
        "\n",
        "# install cached whl next time env is reset to skip costly recompilation\n",
        "if os.path.exists(whlpath):\n",
        "  !pip install {whlpath} --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "y7_nqfcVSzzD"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'nerf_llff_data'\n",
        "experiment   = 'blue-chair'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "qxqjozeh2oy1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75feca8c-3cbe-4779-8d18-329c974b7ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/svox2\n"
          ]
        }
      ],
      "source": [
        "# download super cool tank dataset if its dir is not already present\n",
        "import os\n",
        "%cd /content/svox2\n",
        "# Datasets: from gdrive folder where id is last folder name in url: https://drive.google.com/drive/folders/128yBriW1IG_3NJ5Rp7APSTZsJqdJdfc1\n",
        "gdrive_ids={'TanksAndTempleBG':'1PD4oTP4F8jTtpjd_AQjCsL4h8iYFCyvO',\n",
        "            'nerf_llff_data'  :'16VnMcF1KJYxN9QId6TClMsZRahHNMW5g',\n",
        "            'nerf_real_360'   :'1jzggQ7IPaJJTKx9yLASWHrX8dXHnG5eB',\n",
        "            'nerf_synthetic'  :'18JxhpWD-4ZmuFKLzKlAw-w5PpzZxXOcG'}\n",
        "\n",
        "if not os.path.exists('/content/svox2/data/'+dataset_name):\n",
        "  console_output = !gdown --id {gdrive_ids[dataset_name]} \n",
        "  downloaded_filename = str(console_output).split('To: /content/svox2/')[1].split('\\'')[0]\n",
        "\n",
        "  !mkdir data  &> /dev/null\n",
        "  if '.zip'    in downloaded_filename:\n",
        "    !unzip  -q   {downloaded_filename} -d data\n",
        "  \n",
        "  if '.tar.gz' in downloaded_filename:\n",
        "    !tar   -xf   {downloaded_filename} -C data\n",
        "\n",
        "  # if needed, unify root data dir name and subdir structure since some tar based datasets \n",
        "  # are in aditional subdirs with unique names. but let's have just one root dir named \"data\"\n",
        "  if os.path.exists('/content/svox2/data/'+dataset_name):\n",
        "    !mv data/{dataset_name}/* data/\n",
        "\n",
        "  # remove huge downloaded no longer needed file. \n",
        "  !rm  -f  {downloaded_filename}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install imagemagick"
      ],
      "metadata": {
        "id": "LvO3VQfKPaT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!identify *"
      ],
      "metadata": {
        "id": "7gx44f__VZY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqzaX9yKtRY6"
      },
      "outputs": [],
      "source": [
        "# TO DO: \n",
        "# enable this optional step to upload and colab calibrate your own images \n",
        "# and prepare dataset for svox2 to extract voxels via svox2 (FOLLOW the guide on https://github.com/sxyu/svox2 )\n",
        "# \n",
        "video_to_obj = '/content/drive/MyDrive/UIUC-MCS/445/final/rgbd-bracelets'\n",
        "%cd /content/svox2/opt/scripts\n",
        "\n",
        "#!bash proc_colmap.sh $video_to_obj\n",
        "\n",
        "!python scripts/run_colmap.py video_to_obj\n",
        "!python colmap2nsvf.py video_to_obj/sparse/0\n",
        "!python create_split.py -y video_to_obj\n",
        "\n",
        "#!pip install nerfvis\n",
        "#!python scripts/view_data.py video_to_obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG6WJ_aiV7KP"
      },
      "outputs": [],
      "source": [
        "# launch actual training (remember. 27g ram and 16g gpu for TanksAndTempleBG M60 dataset is needed if selected above)\n",
        "%cd /content/svox2/opt\n",
        "custom_configs={'TanksAndTempleBG':'tnt',\n",
        "                'nerf_llff_data'  :'llff',\n",
        "                'nerf_real_360'   :'llff',\n",
        "                'nerf_synthetic'  :'syn'}\n",
        "!./launch.sh {experiment} 0 ../data/{experiment} -c configs/{custom_configs[dataset_name]}.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/svox2/opt\n",
        "!./launch.sh blue_chair 0  /content/drive/MyDrive/UIUC-MCS/445/final/blue_chair -c configs/custom.json"
      ],
      "metadata": {
        "id": "8n8WVWzwiEz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzGaIuArWuBy"
      },
      "outputs": [],
      "source": [
        "# since training runs detached we can peek at output on demand here when needed\n",
        "#\n",
        "# STOP THIS MANUALLY when training is done!!! when you see \"* Final eval and save\" line in output)\n",
        "# tail -f on itself will never end!!! \n",
        "%cd /content/svox2/opt\n",
        "!tail -f ckpt/{experiment}/log"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "metadata": {
        "id": "47zpjSUidX5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -f ckpt/blue_chair/log"
      ],
      "metadata": {
        "id": "s2gQMoTwcqr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DvAZ6a-xsaEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d119b898-da23-498d-e8c0-4df881783c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 2923354514 May  8 09:54 /content/svox2/opt/ckpt/zeta_tray/ckpt.npz\n"
          ]
        }
      ],
      "source": [
        "# lets see our final resulting trained checkpoint file size when done . official one is 4G\n",
        "!ls -la /content/svox2/opt/ckpt/{experiment}/ckpt.npz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "oGJD2CrXbHOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22fe67cd-2496-40a6-ade0-e8c2582e572a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/svox2/opt\n",
            "backing ckpt zeta_tray to gdrive\n"
          ]
        }
      ],
      "source": [
        "# backup our expensively trained experiment checkpoint to gdrive for future rendering tests even outside of colab if needed \n",
        "# or restore from gdrive if training pass above failed or was skipped\n",
        "import os\n",
        "%cd /content/svox2/opt\n",
        "!mkdir /content/drive/MyDrive/ckpt &> /dev/null\n",
        "\n",
        "# if training was succesfull and produced npz\n",
        "if os.path.exists('/content/svox2/opt/ckpt/'+experiment+'/ckpt.npz'):\n",
        "  print('backing ckpt '+experiment+' to gdrive')\n",
        "  !cp -rf /content/svox2/opt/ckpt/{experiment} /content/drive/MyDrive/ckpt\n",
        "\n",
        "# if not, or was skipped, let's restore checkpoint of this experiment from our gdrive if any is found\n",
        "else:\n",
        "  if os.path.exists('/content/drive/MyDrive/ckpt/'+experiment+'/ckpt.npz'):\n",
        "    print('loading ckpt '+experiment+' from gdrive')\n",
        "    !cp -rf /content/drive/MyDrive/ckpt/{experiment} /content/svox2/opt/ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIUHJyMrQNxS"
      },
      "outputs": [],
      "source": [
        "# (Sadly even thou colab pro has 16gb, it is still just 16g gpu)\n",
        "# SO. If the damn training for too large datasets keeps failing with: out of memory \n",
        "#\n",
        "# Then. Luckily. We can still at least try download already trained checkpoints (thx. to paper authors ;D yay)\n",
        "# And at least start playing with rendering images from various angles\n",
        "#\n",
        "# BUT BEWARE this is 11g gz download if enabled\n",
        "# AND ALSO: if 3-4 downloads happen per 24h of this 11g large file from gdrive, which is highly plausible given usage in this colab. \n",
        "# Then google colab will block further downloads via this gdown api at this particular day for 24h\n",
        "# If that happens. You can still supposedly download it via browser and curl/wget or upload it here by other means I guess?\n",
        "\n",
        "%cd /content/svox2/opt\n",
        "import os\n",
        "\n",
        "# change this to True to enable pretrained checkpoints download. But beware again !!! 11gb file\n",
        "if False:\n",
        "  !mv ckpt ckpt_our\n",
        "  if not os.path.exists('ckpt_tnt.tar.gz'): \n",
        "    !gdown --id 1v9xb5Sd3ulofwNUynC71I_fdwnSLnFhS \n",
        "  !tar -xvf ckpt_tnt.tar.gz  &> /dev/null\n",
        "  !rm  -rf  ckpt_tnt.tar.gz # delete this huge 11g file as fast as possible\n",
        "  !ls -la tnt_equirectlin_fasttv_autoscale/M60/ckpt.npz # check ckpt size for m60. should be around 4g\n",
        "  !mv tnt_equirectlin_fasttv_autoscale ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53KZA1Miqzp7"
      },
      "outputs": [],
      "source": [
        "# finally lets synthetize some sample images from various angles (typically 360 orbit around object) from trained checkpoint / model\n",
        "%cd /content/svox2/opt\n",
        "!python -u render_imgs.py ckpt/{experiment} ../data/{experiment} --no_imsave"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/svox2/opt\n",
        "!python -u render_imgs.py ckpt/{experiment} /content/drive/MyDrive/UIUC-MCS/445/final/zeta_tray --no_imsave"
      ],
      "metadata": {
        "id": "3oUb4EAzSo_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afv5Cik4kOQw"
      },
      "outputs": [],
      "source": [
        "# finally lets synthetize some sample images from various angles (typically 360 orbit around object) from trained checkpoint / model\n",
        "%cd /content/svox2/opt\n",
        "!python -u render_imgs_circle.py ckpt/{experiment} ../data/{experiment}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S86k8ka-VMeU"
      },
      "outputs": [],
      "source": [
        "# finally lets synthetize some sample images from various angles (typically 360 orbit around object) from trained checkpoint / model\n",
        "%cd /content/svox2/opt\n",
        "!python -u render_imgs_circle.py ckpt/{experiment} /content/drive/MyDrive/UIUC-MCS/445/final/zeta_tray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KGModHOcxA8"
      },
      "outputs": [],
      "source": [
        "# finally lets synthetize some sample images from various angles (typically 360 orbit around object) from trained checkpoint / model\n",
        "%cd /content/svox2/opt\n",
        "!python -u render_imgs_circle.py ckpt/{experiment} ../data/{experiment} --traj_type=circle --num_views=100 --vec_up=\"0,-1,-1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_DzNH_vj5Ja"
      },
      "outputs": [],
      "source": [
        "# transfer 3mb of jpgs in zip is more practical than 40mb pngs or hard to inspect mp4 with too aggresive compression\n",
        "%%capture \n",
        "%cd /content/svox2/opt/ckpt/{experiment}/test_renders\n",
        "!for i in *.png; do ffmpeg -i \"$i\" \"${i%.*}.jpg\" &> /dev/null ; done \n",
        "!find . -type f -iname \\*.png -delete\n",
        "%cd /content/svox2/opt\n",
        "!zip -rq images.zip /content/svox2/opt/ckpt/{experiment}/test_renders &> /dev/null "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9F8BfCNZUxx"
      },
      "outputs": [],
      "source": [
        "# copy resulting images to special in html cell visible dir. since html gives bigger output preview flexibility\n",
        "%%capture \n",
        "!cp /content/svox2/opt/ckpt/{experiment}/test_renders/*.* /usr/local/share/jupyter/nbextensions/ &> /dev/null\n",
        "!cp images.zip /usr/local/share/jupyter/nbextensions/ &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzAMVhVQYZX2"
      },
      "outputs": [],
      "source": [
        "# show some sample synthetized images\n",
        "%%html\n",
        "<a href src='/nbextensions/images.zip' download>Download Images</a><br>\n",
        "<img width=\"100%\" src='/nbextensions/0000.jpg' />\n",
        "<img width=\"100%\" src='/nbextensions/0020.jpg' />\n",
        "<img width=\"100%\" src='/nbextensions/0031.jpg' />"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Plenoxels-neurall.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}